{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "#Standard operative procedures for WGS metagenomics @ LDA lab\n",
    "lalcaraz@iecologia.unam.mx\n",
=======
    "#Standard operative procedures for WGS metagenomics @ Environmental Genomics Faculty of Sciences, UNAM lab\n",
    "lalcaraz@ciencias.unam.mx\n",
>>>>>>> 4c3b3d56d3f5f66f4a3190973fb7d828273b4424
    "\n",
    "\n",
    "##Assembly and QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#guardar este script como quieras nombrarlo y ejecutarlo como se indica a continuación:\n",
    "#bash nombre_script.sh <nombre-del-trabajo>\n",
    "#ejecutarlo en un directorio con los archivos crudos de sequenciación (SEQ)\n",
    "#LDA feb 2017\n",
    "\n",
    "SEQS=/home/luis/WGS_metagenomas2017/raw_fastq\n",
    "SALIDAS=/home/luis/WGS_metagenomas2017/raw_fastq\n",
    "BIN=/home/luis/bin/Trimmomatic-0.36\n",
    "BIN2=/home/luis/bin/velvet\n",
    "BIN3=/home/luis/bin/MetaVelvet\n",
    "\n",
    "COUNT=0\n",
    "for FAA in `ls *.gz | perl -pe 's/\\_.*//g' | sort | uniq`\n",
    "do\n",
    "let COUNT=COUNT+1\n",
    "echo \"#!/bin/bash\" >$*.$COUNT.scr\n",
    "echo \"#$ -cwd\" >>$*.$COUNT.scr\n",
    "echo \"#$ -j y\" >>$*.$COUNT.scr\n",
    "echo \"#$ -S /bin/bash\" >>$*.$COUNT.scr\n",
    "echo \"#$ -l h_vmem=12G\" >>$*.$COUNT.scr\n",
    "\n",
    "\n",
    "#Trimmomatic\n",
    "echo \"java -jar $BIN/trimmomatic-0.36.jar PE -threads 2 -phred33 -trimlog trim.log $SEQS/$FAA\"_1.fastq.gz\" $SEQS/$FAA\"_2.fastq.gz\" $SEQS/$FAA\"paired_1.fastq.gz\" $SEQS/$FAA\"unpaired_1.fastq.gz\" $SEQS/$FAA\"paired_2.fastq.gz\" $SEQS/$FAA\"unpaired_2.fastq.gz\" ILLUMINACLIP:$BIN/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36\" >>$*.$COUNT.scr\n",
    "\n",
    "\n",
    "#velveth y velvetg\n",
    "echo  \"$BIN2/velveth $SEQS/$FAA\"_assemblyV3\" 21 -shortPaired -fastq $SEQS/$FAA\"paired_1.fastq.gz\" $SEQS/$FAA\"paired_2.fastq.gz\"\" >>$*.$COUNT.scr \n",
    "echo \"$BIN2/velvetg $SEQS/$FAA\"_assemblyV3\" -exp_cov 2 -ins_length 350\" >>$*.$COUNT.scr\n",
    "\n",
    "#metavelvet\n",
    "#echo \"$BIN3/meta-velvetg $SEQS/$FAA\"_assembly\" -ins_length 350\"  >>$*.$COUNT.scr\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qsub nombre-del-trabajo.scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/perl\n",
    "#remove small contigs; por ejemplo de al menos 100 pb:\n",
    "#for N in `ls */*.fa`; do echo \"perl small.pl 100 $N > $N\"l100.fa\"\" ; done | bash\n",
    "use strict;\n",
    "use warnings;\n",
    " \n",
    "my $minlen = shift or die \"Error: `minlen` parameter not provided\\n\";\n",
    "{\n",
    "    local $/=\">\";\n",
    "    while(<>) {\n",
    "        chomp;\n",
    "        next unless /\\w/;\n",
    "        s/>$//gs;\n",
    "        my @chunk = split /\\n/;\n",
    "        my $header = shift @chunk;\n",
    "        my $seqlen = length join \"\", @chunk;\n",
    "        print \">$_\" if($seqlen >= $minlen);\n",
    "    }\n",
    "    local $/=\"\\n\";\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Gene prediction & annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Prodigal descarga y parámetros para correr\n",
    "wget https://github.com/hyattpd/Prodigal/releases/download/v2.6.3/prodigal.linux\n",
    "chmod +x prodigal.linux \n",
    "for N in `ls *.fas`; do echo \"qsub -N $N.scr -b y -j y -cwd -V \\\"/home/luis/bin/prodigal.linux -a $N.faa -p meta -i $N\\\"\"; done | bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#Se parte el fasta resultante entre el número de trabajos que se quiere enviar\n",
    "#prc es el número de trabajos que se quiere enviar, en este cluster tenemos 40 núcleos,\n",
    "#pero si le pedimos que use dos procesadores por trabajo lo dividimos en 20, modificar el valor\n",
    "#prc de acuerdo a necesidades\n",
    "#ejecutar: $~/bash nombre_script | bash  \n",
    "\n",
    "seqs=`grep -c \">\" $*`\n",
    "prc=20\n",
    "parte=$((seqs/prc))\n",
    "echo \"perl /usr/local/bin/partefasta $parte $*\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#En este bucle se mandan los trabajos a la cola para correr el programa eggnog-mapper\n",
    "#utilizando la base de datos de bacterias, se piden 2 procesadores por proceso y se mandan al \n",
    "#cluster. Puedes cambiar el *.fas por cualquier otro wildcard. Es muy importante corregir\n",
    "#los directorios de salida a un directorio donde tengan permisos de escritura. \n",
    "\n",
    "for N in `ls *.fas`; do echo \"qsub -pe completenode 2 -N $N -b y -j y -cwd -V \"python /databases/eggnog-mapper/emapper.py -i /databases/test/$N -o /databases/test/out$N -d bact --cpu 2\"\"; done  | bash\n",
    "\n",
    "#Cuando terminan los trabajos hay que concatenar las salidas:\n",
    "\n",
    "cat *.annotations | grep -v \"#\" >outcca.annotation\n",
    "cat *.hmm_hits | grep -v \"#\" >outcca.hmm_hit\n",
    "cat *.seed_orthologs | grep -v \"#\" >outcca.seed_ortholog\n",
    "\n",
    "#La explicación de los reultados la pueden encontrar aquí: https://github.com/jhcepas/eggnog-mapper/wiki/Results-Interpretation#project_nameemapperhmm_hits-file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#anotación por m5nr (local) en deep-though\n",
    "#las bases de datos se encuentran disponibles en deep-thought en /databases\n",
    "\n",
    "#ejermplo: blastp -db /databases/m5nr16may17/m5nr16may17 -word_size 6 -query /databases/test/cca.faa.0.fas -outfmt 6 -evalue 1e-10 -num_alignments 10 -num_threads 2 -out /databases/test/blastcca.faa.0.fas.bout\n",
    "#para correr el comando en todos los nodos de deep-thought, con archivos de entrada terminados en *.fas:\n",
    "\n",
    "#Correr con diamond!!\n",
    "\n",
    "for N in `ls cca*.fas`; do echo \"qsub -pe completenode 2 -N $N -b y -j y -cwd -V \\\"/home/luis/diamond blastp -p 2 -d /databases/m5nr16may17/m5nr.dmnd -q $N --outfmt 6 -e 1e-10 -o diamond$N.bout\"\n",
    "\n",
    "\n",
    "#for N in `ls cca*.fas`; do echo \"qsub -pe completenode 2 -N $N -b y -j y -cwd -V \\\"blastp -db /databases/m5nr16may17/m5nr16may17 -word_size 6 -query /databases/test/$N -outfmt 6 -evalue 1e-10 -num_alignments 10 -num_threads 2 -out /databases/test/blast$N.bout\\\"\"; done | bash\n",
    "#ten cuidado de revisar las rutas completas de ejecución, bases de datos y directorios de salida. \n",
    "\n",
    "#oneliner para concatenar salidas de blast, ordenarlas por valor de bitscore, remover duplicados con el mismo valor de bitscore se guardan en el archivo: best_uniq\n",
    "cat *.bout | perl -pe ' $name_col=0; $score_col=11; while(<>) { s/\\r?\\n//; @F=split /\\t/, $_; ($n, $s) = @F[$name_col, $score_col]; if (! exists($max{$n})) { push @names, $n }; if (! exists($max{$n}) || $s > $max{$n}) { $max{$n} = $s; $best{$n} = () }; if ($s == $max{$n}) { $best{$n} .= \"$_\\n\" }; } for $n (@names) { print $best{$n} } ' >best;  perl -e ' $column=0; $unique=0; while(<>) { s/\\r?\\n//; @F=split /\\t/, $_; if (! ($save{$F[$column]}++)) { print \"$_\\n\"; $unique++ } } ' best >best_uniq; rm best\n",
    "awk '{print $1\"\\t\"$3\"\\t\"$11\"\\t\"$12\"\\t\"$2}' best_uniq.tsv >best.simple.tsv #ligero reacomodo de columnas para la anotación en los siguientes pasos. \n",
    "\n",
    "cut -f2 best_uniq >test2 #identificadores de md5 para buscar en RAST-\n",
    "/databases/SUBSYSTEMS.tsv #este archivo se obtuvo del api del RAST descargando todos los subsistemas, se filtro y edito manualmente\n",
    "# http://api.metagenomics.anl.gov/1/m5nr/ontology?source=Subsystems&min_level=function obtener todo el json de la \n",
    "1285  perl -e ' $col1=9; $col2=0; ($f1,$f2)=@ARGV; open(F2,$f2); while (<F2>) { s/\\r?\\n//; @F=split /\\t/, $_; $line2{$F[$col2]} .= \"$_\\n\" }; $count2 = $.; open(F1,$f1); while (<F1>) { s/\\r?\\n//; @F=split /\\t/, $_; $x = $line2{$F[$col1]}; if ($x) { $num_changes = ($x =~ s/^/$_\\t/gm); print $x; $merged += $num_changes } } warn \"\\nJoining $f1 column $col1 with $f2 column $col2\\n$f1: $. lines\\n$f2: $count2 lines\\nMerged file: $merged lines\\n\"; ' simple+genbank+subsystems SUBSYSTEMS.tsv >complete.tsv\n",
    " \n",
    "#editar la salida y quitar redundancia de md5 y otros identificadores se sugiere el siguiente orden:\n",
    "#protein\t%id\tE-value\tbitscore\tmd5\tAccesion\tGenbank annotation\tBest_hit\tSubsystem\tAnnotation subsystems\tLevel1\tLevel2\tLevel3\tLevel4\n",
    "#cca_assembly_6\t100\t1E-113\t336\t906aad964cdabaf371a78677aef566eb\tEAY63195.1\tPrimosomal protein n\tBurkholderia cenocepacia PC184\tSS23169\tHelicase PriA essential for oriC/DnaA-independent DNA replication\tDNA Metabolism\tDNA replication\tDNA-replication\tHelicase PriA essential for oriC/DnaA-independent DNA replication\n",
    "\n",
    "#sources M5NR http://api.metagenomics.anl.gov/m5nr/sources\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "#para correr múltiples anotaciones en varios archivos hice este script (anota.sh) :\n",
    "for N in `ls *.bout`; \n",
    "do\n",
    "/databases/myM5NR/bin/m5nr-tools.pl --api http://api.metagenomics.anl.gov --option annotation --source RefSeq --md5 $N.best_uniq.busca | perl -pe ' $column=1; $unique=0; while(<>) { s/\\r?\\n//; @F=split /\\t/, $_; if (! ($save{$F[$column]}++)) { print \"$_\\n\"; $unique++ } } ' >$N.annotation_refseq;\n",
    "/databases/myM5NR/bin/m5nr-tools.pl --api http://api.metagenomics.anl.gov --option annotation --source Subsystems --md5 $N.best_uniq.busca| perl -pe ' $column=1; $unique=0; while(<>) { s/\\r?\\n//; @F=split /\\t/, $_; if (! ($save{$F[$column]}++)) { print \"$_\\n\"; $unique++ } } ' >$N.annotation_Subsystems;\n",
    "/databases/myM5NR/bin/m5nr-tools.pl --api http://api.metagenomics.anl.gov --option annotation --source SEED --md5 $N.best_uniq.busca | perl -pe ' $column=1; $unique=0; while(<>) { s/\\r?\\n//; @F=split /\\t/, $_; if (! ($save{$F[$column]}++)) { print \"$_\\n\"; $unique++ } } ' >$N.annotation_Seed;\n",
    "perl -e ' $col1=1; $col2=1; ($f1,$f2)=@ARGV; open(F2,$f2); while (<F2>) { s/\\r?\\n//; @F=split /\\t/, $_; $line2{$F[$col2]} .= \"$_\\n\" }; $count2 = $.; open(F1,$f1); while (<F1>) { s/\\r?\\n//; @F=split /\\t/, $_; $x = $line2{$F[$col1]}; if ($x) { $num_changes = ($x =~ s/^/$_\\t/gm); print $x; $merged += $num_changes } } warn \"\\nJoining $f1 column $col1 with $f2 column $col2\\n$f1: $. lines\\n$f2: $count2 lines\\nMerged file: $merged lines\\n\"; ' $N.best_uniq $N.annotation_refseq  | cut -f1,2,3,10,11,13,15,16 >$N.hits+seed\n",
    "perl -e ' $col1=1; $col2=1; ($f1,$f2)=@ARGV; open(F2,$f2); while (<F2>) { s/\\r?\\n//; @F=split /\\t/, $_; $line2{$F[$col2]} .= \"$_\\n\" }; $count2 = $.; open(F1,$f1); while (<F1>) { s/\\r?\\n//; @F=split /\\t/, $_; $x = $line2{$F[$col1]}; if ($x) { $num_changes = ($x =~ s/^/$_\\t/gm); print $x; $merged += $num_changes } } warn \"\\nJoining $f1 column $col1 with $f2 column $col2\\n$f1: $. lines\\n$f2: $count2 lines\\nMerged file: $merged lines\\n\"; ' $N.hits+seed $N.annotation_Subsystems| cut -f1-9 >$N.seed+subsystems;\n",
    "#revisar\n",
    "perl -e ' $col1=8; $col2=0; ($f1,$f2)=@ARGV; open(F2,$f2); while (<F2>) { s/\\r?\\n//; @F=split /\\t/, $_; $line2{$F[$col2]} .= \"$_\\n\" }; $count2 = $.; open(F1,$f1); while (<F1>) { s/\\r?\\n//; @F=split /\\t/, $_; $x = $line2{$F[$col1]}; if ($x) { $num_changes = ($x =~ s/^/$_\\t/gm); print $x; $merged += $num_changes } } warn \"\\nJoining $f1 column $col1 with $f2 column $col2\\n$f1: $. lines\\n$f2: $count2 lines\\nMerged file: $merged lines\\n\"; ' $N.seed+subsystems SUBSYSTEMS.tsv | cut -f1-8,10-14  >$N.seed+refseq+subsystems.tsv; \n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "##spliter para archivos multifastas en formato de >secuencia_1 >seq_3 toma los nombres de las muestras y separa a multifastas individuales (pasar de repset o concatenados a archivos individuales)\n",
    "echo obtaining sequence tags of $*\n",
    "grep '>' $* | perl -pe 's/\\_.*$//g;s/\\>//g' | uniq >$*.samples\n",
    "\n",
    "echo \"/^$/    { next; }\" >splitter.awk\n",
    "echo \"/^>/    { filename=\\\"$*.WARNING.notmatched\\\";}\" >>splitter.awk\n",
    "\n",
    "for SUBMIT in `cat $*.samples`\n",
    "do\n",
    "\n",
    "echo \"/^>$SUBMIT/   { filename=\\\"$SUBMIT.fna\\\"; }\" >>splitter.awk\n",
    "    \n",
    "\n",
    "done\n",
    "\n",
    "echo \"{ print >> filename;}\" >>splitter.awk\n",
    "\n",
    "# cat splitter.awk\n",
    "\n",
    "awk -f splitter.awk $*\n",
    "\n",
    "echo \"this is all folks\"\n",
    "\n",
    "#EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#anotaciòn por m5nr patung \n",
    "#hay que generar los archivos condor y los scripts para hacerlos correr en el sistema de colas condor. \n",
    "#usar un archivo header que contenga solamente: #!/bin/bash\n",
    "\n",
    "for N in `ls *.fas`; do echo \"executable = $N.sh\"  >$N.condor; echo \"output = $N.out\" >>$N.condor; echo \"error =$N.out\"  >>$N.condor; echo \"log = $N.out\" >>$N.condor; echo \"request_cpus = 2\" >>$N.condor; echo \"queue 1\" >>$N.condor; chmod +x *.condor; done\n",
    "\n",
    "for N in `ls *.fas`; do cat header >$N.sh  ; echo \"date\" >>$N.sh; echo \"/srv/home/lalcaraz/bin/blastp -query /srv/home/lalcaraz/shama/$N -db /srv/home/lalcaraz/m5nr16may17/m5nr16may17 -word_size 6 -outfmt 6 -evalue 1e-10 -num_alignments 10 -num_threads 2 -out /srv/home/lalcaraz/shama/$N.bout\" >>$N.sh ; echo \"date\" >>$N.sh; chmod +x *.sh ; done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Taxonomic binning & assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kraken estas instrucciones son para correrlo en el cluster de Lancis patung\n",
    "\n",
    "for N in `ls *.fas`; do echo \"executable = $N.sh\"  >$N.condor; echo \"output = $N.out\" >>$N.condor; echo \"error =$N.out\"  >>$N.condor; echo \"log = $N.out\" >>$N.condor; echo \"request_cpus = 20\" >>$N.condor; echo \"queue 1\" >>$N.condor; chmod +x *.condor; done\n",
    "\n",
    "for N in `ls *.fas`; do cat header >$N.sh  ; echo \"date\" >>$N.sh; echo \"/srv/home/lalcaraz/bin/kraken --db /srv/home/lalcaraz/ --fasta_input $N --threads 40 --output $N.kraken\" >>$N.sh ;echo \"date\">>$N.sh; chmod +x *.sh ; done\n",
    "\n",
    "#El archivo header solo contiene un: #!/bin/bash\n",
    "\n",
    "for N in `ls *.kraken`; do kraken-translate --mpa-format --db /srv/home/lalcaraz/ $N >tax.$N; done\n",
    "\n",
    "#todo en uno\n",
    "for N in `ls tax.*`;do cat $N | perl -pe 's/_cov_/\\t/g;s/\\|/\\t/g' >$N.tmp;  awk 'FNR==NR{if(m<NF)m=NF;next}{for(i=NF;i<m;i++)$(i+1)=\"\\tNA\"}1' $N.tmp $N.tmp >$N.parsed; rm $N.tmp; done\n",
    "\n",
    "\n",
    "#por partes, si ya hiciste el último paso es la unión de los dos siguientes:\n",
    "cat tax.$N.kraken  | perl -pe's/_cov_/\\t/g;s/\\|/\\t/g' >test #en este caso era un ensamblado de velvet, se utiliza la cobertura como una métrica y se pone como una columna separada\n",
    "awk 'FNR==NR{if(m<NF)m=NF;next}{for(i=NF;i<m;i++)$(i+1)=\"\\tNA\"}1' test test   >split.txt #en esta linea se evalua la cantidad de columnas máximas, la salida no es homogenea, si no encuentra el número igual rellena con NAs separados por tabuladores\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
